\section{Kaldi}
\subsection{Сборка}
\begin{lstlisting}[caption={Сборка Kaldi}, label=kaldi:build]
    $ git clone https://github.com/kaldi-asr/kaldi
    $ cd kaldi
    $ cd tools
    $ extras/check_dependencies.sh
    $ make
    $ cd ../src
    $ ./configure --shared
    $ make
\end{lstlisting}

Для сборки данного инструмента необходимо выполнить команды
представленные в листинге~\ref{kaldi:build}. Данный процесс займёт много времени.
Также необходимо скачать готовую языковую модель для русского языка, которая
будет использоваться для запуска \textit{kaldi}.

\begin{minipage}{\textwidth}

\begin{lstlisting}[caption={Структура языковой модели}, label={kaldi:model}]
$ tree exp/tdnn
exp/tdnn
|- conf
|   |- ivector_extractor.conf
|   |- mfcc.conf
|   |- online_cmvn.conf
|   |- online.conf
|   └- splice.conf
|- final.mdl
|- frame_subsampling_factor
|- graph
|   |- disambig_tid.int
|   |- HCLG.fst
|   |- num_pdfs
|   |- phones.txt
|   └- words.txt
|- ivector_extractor
|   |- final.dubm
|   |- final.ie
|   |- final.mat
|   |- global_cmvn.stats
|   |- online_cmvn.conf
|   └- splice_opts
└- tree
\end{lstlisting}
\end{minipage}


После сборки скачиваем языковую модель. Иерархия файлов модели представлена
в выводе команды \texttt{tree} в листинге~\ref{kaldi:model}. Данная модель
расположена в папке \texttt{/home/user/project/tdnn}.

\subsection{Запуск}
\begin{lstlisting}[caption={Запуск tcp-сервера},label={kaldi:run},language=bash]
#!/bin/bash
MODEL="${PWD}/exp/tdnn"

./kaldi/src/online2bin/online2-tcp-nnet3-decode-faster \
    --samp-freq=8000 --frames-per-chunk=20 \
    --extra-left-context-initial=0 --frame-subsampling-factor=3 \
    --config=${MODEL}/conf/online.conf --min-active=200 \
    --max-active=7000 --beam=15.0 --lattice-beam=6.0 \
    --acoustic-scale=1.0 --port-num=5050 \
    ${MODEL}/final.mdl ${MODEL}/graph/HCLG.fst \
    ${MODEL}/graph/words.txt
\end{lstlisting}

\begin{lstlisting}[caption={Передача аудио-файла на распознавание речи},label={kaldi:run:check},language=bash]
$ sox sample.wav -t raw -c 1 -b 16 -r 8k -e signed-integer - | nc -N localhost 5050
\end{lstlisting}

Для запуска и проверки работоспособности запустим tcp-сервер командой~\ref{kaldi:run}.
После передадим аудио-файл в формате \textit{wav} в tcp-сервер командной~\ref{kaldi:run:check}.
Распознанный текст совпадает с тем, что было в данном аудио-файле.

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption={Результат работы сервера распознавания речи}, label={kaldi:run:res},language=bash]
# родион потапыч высчитывал каждый новый вершок углубление и давно определил про себя
\end{lstlisting}
\end{minipage}

\subsection{Конфигурация}

В листинге~\ref{kaldi:run} был представлен скрипт для запуска, в нём были
использованы опции, которые позволяют настроить \textit{kaldi}, чтобы улучшить
процесс распознавания речи в требуемой среде. Это необходимо, потому что
аудио-поток может поступать с различных источников, которые могут изменить качество
потока.

Рассмотрим некоторые опции:
\begin{itemize}
    \item sample-freq~---~частота дискретизации, на которой работает сервер и способен производить распознавания.
        По скольку аудио-поток с телефонных апаратов по умолчанию равен 8kHz, то и сервер работает на данной частоте;
    \item frames-per-chunk~---~количество чанков в секудну;
    \item extra-left-context~---~количество дополнительных чанков в начале;
    \item frame-subsampling-factor~---~фактор субдискретизации;
    \item config~---~путь до файла дополнительных настроек. Путь указан до настроек, прилагаемых с моделью;
    \item min-active~---~минимальное количество состояний декодера;
    \item max-active~---~максимальное количество состояний декодера. Чем больше число, тем лучше распознавание, но дольше;
    \item beam~---~декодирование луча. Чем больше число, тем дольше и лучше распознавание;
    \item lattice-beam~---~размер решётки для генерации. Чем больше число, тем дольше и лучше распознавание;
    \item acoustic-scale~---~Коэффициент масштабирования для вероятностей акустического правдоподобия.
\end{itemize}
